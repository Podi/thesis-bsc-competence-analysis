{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530df508-24b1-4acf-8bdc-8810a38a76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8f1ba-48ca-4c95-a96a-4b0c0af5f190",
   "metadata": {},
   "source": [
    "INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0efcd16-6be9-459b-9600-ebdecde613f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encode the corpus. This might take a while\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 25/25 [00:02<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start clustering\n",
      "Clustering done after 0.21 sec\n",
      "\n",
      "Cluster 1, #84 Elements \n",
      "\t application developer\n",
      "\t application developer\n",
      "\t system engineer\n",
      "\t ...\n",
      "\t software engineer\n",
      "\t system engineer\n",
      "\t system engineer\n",
      "\n",
      "Cluster 2, #66 Elements \n",
      "\t system analyst\n",
      "\t system analyst\n",
      "\t computer system analyst\n",
      "\t ...\n",
      "\t business system analyst\n",
      "\t system analyst system analyst principal system analyst\n",
      "\t information technology business analyst\n",
      "\n",
      "Cluster 3, #33 Elements \n",
      "\t quality assurance specialist\n",
      "\t quality assurance analyst\n",
      "\t software quality assurance engineer\n",
      "\t ...\n",
      "\t quality assurance test engineer\n",
      "\t quality assurance engineer\n",
      "\t quality assurance engineer\n",
      "\n",
      "Cluster 4, #29 Elements \n",
      "\t data integration specialist intermediate\n",
      "\t data integration warehouse engineer\n",
      "\t data architect\n",
      "\t ...\n",
      "\t data architect professional service\n",
      "\t data architect\n",
      "\t data architect\n",
      "\n",
      "Cluster 5, #28 Elements \n",
      "\t data analyst\n",
      "\t data integration specialist\n",
      "\t data engineer\n",
      "\t ...\n",
      "\t data engineer\n",
      "\t data engineer\n",
      "\t data analyst\n",
      "\n",
      "Cluster 6, #27 Elements \n",
      "\t level software engineer\n",
      "\t associate software engineer\n",
      "\t system software developer\n",
      "\t ...\n",
      "\t software architect\n",
      "\t manager software engineer\n",
      "\t principal engineer software engineering\n",
      "\n",
      "Cluster 7, #27 Elements \n",
      "\t information technology specialist\n",
      "\t information technology specialist\n",
      "\t information technology acquisition analyst\n",
      "\t ...\n",
      "\t technology analyst\n",
      "\t information technology application analyst\n",
      "\t information technology business analyst information technology business analyst\n",
      "\n",
      "Cluster 8, #27 Elements \n",
      "\t solution architect\n",
      "\t solution architect\n",
      "\t integration solution architect\n",
      "\t ...\n",
      "\t enterprise solution architect\n",
      "\t digital solution architect\n",
      "\t solution architect voice\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "# Model for computing sentence embeddings. We use one trained for similar questions detection\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "df = pd.read_csv('input/preprocessed_jobs_all.csv')\n",
    "prep_titles = df['title']\n",
    "\n",
    "prep_desprep_titlescriptions = list(prep_titles)\n",
    "print(\"Encode the corpus. This might take a while\")\n",
    "corpus_embeddings = model.encode(prep_titles, batch_size=64, show_progress_bar=True, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "print(\"Start clustering\")\n",
    "start_time = time.time()\n",
    "\n",
    "#Two parameters to tune:\n",
    "#min_cluster_size: Only consider cluster that have at least 25 elements\n",
    "#threshold: Consider sentence pairs with a cosine-similarity larger than threshold as similar\n",
    "clusters = util.community_detection(corpus_embeddings, min_community_size=25, threshold=0.75)\n",
    "\n",
    "print(\"Clustering done after {:.2f} sec\".format(time.time() - start_time))\n",
    "\n",
    "#Print for all clusters the top 3 and bottom 3 elements\n",
    "for i, cluster in enumerate(clusters):\n",
    "    print(\"\\nCluster {}, #{} Elements \".format(i+1, len(cluster)))\n",
    "    for sentence_id in cluster[0:3]:\n",
    "        print(\"\\t\", prep_titles[sentence_id])\n",
    "    print(\"\\t\", \"...\")\n",
    "    for sentence_id in cluster[-3:]:\n",
    "        print(\"\\t\", prep_titles[sentence_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
